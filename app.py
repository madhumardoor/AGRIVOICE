# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PUTUD9PVElbly0LTiV5hQ1z6LdHzp50p
"""

!pip install streamlit
!pip install openai
!pip install faiss-cpu
!pip install sentence-transformers

import streamlit as st
import faiss
import numpy as np
import os
import google.generativeai as genai
from sentence_transformers import SentenceTransformer

# Securely load API key
API_KEY = os.getenv("GOOGLE_API_KEY")

if not API_KEY:
    st.error("‚ö†Ô∏è API Key is missing! Please set GOOGLE_API_KEY as an environment variable.")
    st.stop()

# Configure Gemini API
genai.configure(api_key=API_KEY)

# Load FAISS vector database
try:
    index = faiss.read_index("agri_vector.index")
except:
    st.error("‚ö†Ô∏è Error loading FAISS index file. Ensure `agri_vector.index` exists.")
    st.stop()

# Load embedding model
model = SentenceTransformer("all-MiniLM-L6-v2")

# Sample stored documents (should be loaded dynamically in production)
documents = [
    "How to improve soil fertility?",
    "Best irrigation techniques for rice farming",
    "Effective pest control methods in agriculture",
    "How to increase crop yield efficiently?"
]

# Streamlit UI
st.title("üå± AgriVoice: AI-Powered Agricultural Chatbot")

query = st.text_input("üîç Ask an agricultural question:")

if st.button("Search"):
    if not query.strip():
        st.warning("‚ö†Ô∏è Please enter a question!")
    else:
        # Encode query
        query_embedding = model.encode([query])
        query_embedding = np.array(query_embedding).reshape(1, -1)

        # Search FAISS index for top matches
        D, I = index.search(query_embedding, k=2)
        retrieved_text = [documents[i] for i in I[0] if 0 <= i < len(documents)]

        st.subheader("üîç Relevant Context Found:")
        for i, text in enumerate(retrieved_text, 1):
            st.write(f"**{i}.** {text}")

        # Generate response using Gemini
        model_gemini = genai.GenerativeModel("gemini-1.5-pro-latest")

        try:
            response = model_gemini.generate_content([
                f"Based on this info: {retrieved_text}, {query}"
            ])
            st.subheader("ü§ñ Gemini AI Response:")
            st.write(response.text)
        except Exception as e:
            st.error(f"‚ö†Ô∏è API Error: {str(e)}")

