# -*- coding: utf-8 -*-
"""Vector database.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sVZZwhSxyqbXRiTh0U7k9iwaysWEVVsi

Integrate a Vector Database
"""

!pip install faiss-cpu

from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

# Load embedding model
model = SentenceTransformer("all-MiniLM-L6-v2")

# Sample agricultural data
documents = [
    # Rice Crop Health Monitoring
    "How to detect rice leaf diseases using deep learning?",
    "Best machine learning techniques for rice yield prediction",
    "Using satellite imagery for rice crop monitoring",
    "Impact of soil nutrients on rice growth",
    "Real-time pest detection in rice fields using AI",

    # General Agricultural Applications
    "Smart irrigation systems using IoT and AI",
    "AI-based weed detection and removal",
    "How climate change affects crop productivity",
    "Precision agriculture techniques for sustainable farming",
    "Using drone technology for crop monitoring",
    "Soil moisture prediction using machine learning",
    "Automated pest detection in agriculture",
    "Enhancing crop rotation planning using AI",
    "Predicting market demand for agricultural products with ML"
]

# Convert text to embeddings
embeddings = model.encode(documents)

# Print embedding shape
print("Embedding shape:", embeddings.shape)

# Create FAISS index
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)

# Ensure embeddings are in correct format
embeddings = np.array(embeddings, dtype=np.float32)

# Add to index
index.add(embeddings)
print("FAISS index created and populated.")

# Save index
faiss.write_index(index, "agri_vector.index")
print("Index saved successfully.")

"""Modify Retrieval Process to Use Vector Database"""

import os
import faiss
import numpy as np
import google.generativeai as genai
from sentence_transformers import SentenceTransformer

import google.generativeai as genai

# Load embedding model
model = SentenceTransformer("all-MiniLM-L6-v2")

# Load FAISS index
index = faiss.read_index("agri_vector.index")

# stored documents (should be dynamically loaded in real use cases)
documents = [
    "How to improve soil fertility?",
    "Best irrigation techniques for rice farming",
    "Effective pest control methods in agriculture",
    "How to increase crop yield efficiently?"
]

# Encode user query
query = "How do I increase crop yield?"
query_embedding = model.encode([query])

# Ensure FAISS-compatible shape
query_embedding = np.array(query_embedding).reshape(1, -1)

# Search in FAISS
D, I = index.search(query_embedding, k=2)  # Retrieve top 2 matches

# Retrieve relevant text
retrieved_text = [documents[i] for i in I[0] if 0 <= i < len(documents)]  # âœ… Avoid out-of-bounds error

# Use retrieved context with Gemini
messages = [
    "You are an expert in agriculture.",
    f"Based on this info: {retrieved_text}, {query}"
]

# ðŸ”¥ Call Gemini API
model = genai.GenerativeModel("gemini-1.5-pro-latest")  # Use a valid model
response = model.generate_content(messages)

# Print Gemini's response
print(response.text)

